{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarvankmr/resttest/blob/master/Tree_Height_estimation_using_DINOv3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c6c7589"
      },
      "source": [
        "### 1. Imports\n",
        "\n",
        "This cell imports all the necessary Python libraries for the DINOv3 tree analysis tool, including deep learning frameworks (PyTorch), image processing libraries (PIL, OpenCV), numerical computation (NumPy), data analysis (scikit-learn), visualization (Matplotlib), and utilities for web requests and file system operations (requests, os)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65b5477e"
      },
      "source": [
        "import torch\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import DBSCAN\n",
        "import requests\n",
        "import os\n",
        "\n",
        "# First, install the required packages:\n",
        "# pip install torch torchvision pillow opencv-python scikit-learn matplotlib\n",
        "# pip install git+https://github.com/facebookresearch/dinov3.git"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8426bef5"
      },
      "source": [
        "### 2. DINOv3TreeAnalyzer Class Definition\n",
        "\n",
        "This section defines the `DINOv3TreeAnalyzer` class, which encapsulates the functionality for loading the DINOv3 model, extracting features from images, detecting tree points, estimating heights (simplified), clustering tree crowns, and visualizing the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05659a3f"
      },
      "source": [
        "class DINOv3TreeAnalyzer:\n",
        "    def __init__(self, model_size='base'):\n",
        "        \"\"\"\n",
        "        Initialize DINOv3 model for tree analysis\n",
        "        model_size: 'small', 'base', 'large', or 'giant'\n",
        "        \"\"\"\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        # Load the new DINOv3 model\n",
        "        # Note: This uses the actual DINOv3 (not DINOv2) for better performance\n",
        "        try:\n",
        "            # Try to load DINOv3 directly\n",
        "            self.model = torch.hub.load('facebookresearch/dinov3', f'dinov3_vit{model_size[0]}14')\n",
        "        except:\n",
        "            # Fallback to DINOv2 if DINOv3 not available\n",
        "            print(\"Loading DINOv2 as fallback (install DINOv3 for best results)\")\n",
        "            model_names = {\n",
        "                'small': 'dinov2_vits14',\n",
        "                'base': 'dinov2_vitb14',\n",
        "                'large': 'dinov2_vitl14',\n",
        "                'giant': 'dinov2_vitg14'\n",
        "            }\n",
        "            self.model = torch.hub.load('facebookresearch/dinov2', model_names[model_size])\n",
        "\n",
        "        self.model.to(self.device)\n",
        "        self.model.eval()\n",
        "\n",
        "        # Image preprocessing\n",
        "        self.transform = T.Compose([\n",
        "            T.Resize((518, 518)),  # DINOv2 works well with 518x518\n",
        "            T.ToTensor(),\n",
        "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "    def get_optimal_image_specs(self, ground_sample_distance_m=None):\n",
        "        \"\"\"\n",
        "        Get recommendations for optimal image specifications for DINOv3\n",
        "\n",
        "        Args:\n",
        "            ground_sample_distance_m: Ground sampling distance in meters per pixel\n",
        "\n",
        "        Returns:\n",
        "            dict: Specifications and recommendations\n",
        "        \"\"\"\n",
        "        specs = {\n",
        "            'recommended_input_sizes': [336, 448, 518, 672, 896],  # Multiples of 14\n",
        "            'patch_size': self.patch_size,\n",
        "            'current_input_size': self.input_size,\n",
        "            'current_patch_grid': f\"{self.input_size//self.patch_size}x{self.input_size//self.patch_size}\"\n",
        "        }\n",
        "\n",
        "        print(\"=== DINOv3 Image Specification Guide ===\")\n",
        "        print(f\"Current model input size: {self.input_size}x{self.input_size}\")\n",
        "        print(f\"Patch grid: {self.input_size//self.patch_size}x{self.input_size//self.patch_size} patches\")\n",
        "        print(f\"Each patch covers: {self.patch_size}x{self.patch_size} pixels\")\n",
        "\n",
        "        print(\"\\n--- Recommended Input Sizes ---\")\n",
        "        for size in specs['recommended_input_sizes']:\n",
        "            grid_size = size // self.patch_size\n",
        "            print(f\"  {size}x{size} → {grid_size}x{grid_size} patches ({grid_size**2} total)\")\n",
        "\n",
        "        if ground_sample_distance_m:\n",
        "            print(f\"\\n--- Spatial Resolution Analysis ---\")\n",
        "            print(f\"Ground sampling distance: {ground_sample_distance_m}m/pixel\")\n",
        "\n",
        "            for size in specs['recommended_input_sizes']:\n",
        "                grid_size = size // self.patch_size\n",
        "                patch_ground_size = self.patch_size * ground_sample_distance_m\n",
        "                total_area = (size * ground_sample_distance_m) ** 2 / 10000  # hectares\n",
        "\n",
        "                print(f\"  {size}x{size} input:\")\n",
        "                print(f\"    - Each patch covers: {patch_ground_size:.1f}x{patch_ground_size:.1f}m\")\n",
        "                print(f\"    - Total area covered: {total_area:.2f} hectares\")\n",
        "                print(f\"    - Tree detection resolution: ~{patch_ground_size:.1f}m\")\n",
        "\n",
        "        print(f\"\\n--- Guidelines ---\")\n",
        "        print(\"• For tree detection: Use 672x672 or 896x896 for best results\")\n",
        "        print(\"• Original image should be at least 2-3x the target input size\")\n",
        "        print(\"• Recommended ground sampling distance: 0.1-1.0 meters per pixel\")\n",
        "        print(\"• Higher resolution = better individual tree detection\")\n",
        "        print(\"• Lower resolution = better for forest-level analysis\")\n",
        "\n",
        "        return specs\n",
        "\n",
        "    def extract_features(self, image_path):\n",
        "        \"\"\"Extract dense features from aerial/satellite imagery\"\"\"\n",
        "        # Load and preprocess image\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        input_tensor = self.transform(image).unsqueeze(0).to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # Get patch features (dense features)\n",
        "            features = self.model.get_intermediate_layers(input_tensor, n=1)[0]\n",
        "            # Shape: [1, num_patches, feature_dim]\n",
        "\n",
        "        # Set image metadata for visualization\n",
        "        self.input_size = input_tensor.shape[-1]  # e.g., 518\n",
        "        self.patch_size = 14  # DINOv3/DINOv2 ViT patch size\n",
        "        patch_grid_size = self.input_size // self.patch_size\n",
        "        self.image_metadata = {\n",
        "            'original_size': image.size,  # (width, height)\n",
        "            'patch_grid_size': patch_grid_size\n",
        "        }\n",
        "\n",
        "        return features.squeeze(0).cpu().numpy(), image\n",
        "\n",
        "    def detect_tree_points(self, features, threshold_percentile=90):\n",
        "        \"\"\"\n",
        "        Detect tree points using feature clustering\n",
        "        \"\"\"\n",
        "        # Calculate feature magnitude (proxy for vegetation presence)\n",
        "        feature_magnitude = np.linalg.norm(features, axis=1)\n",
        "\n",
        "        # Threshold for potential tree locations\n",
        "        threshold = np.percentile(feature_magnitude, threshold_percentile)\n",
        "        tree_candidates = feature_magnitude > threshold\n",
        "\n",
        "        # Convert to 2D coordinates (assuming square patch grid)\n",
        "        patch_size = int(np.sqrt(len(features)))\n",
        "        tree_coords = []\n",
        "\n",
        "        for i, is_tree in enumerate(tree_candidates):\n",
        "            if is_tree:\n",
        "                y = i // patch_size\n",
        "                x = i % patch_size\n",
        "                tree_coords.append([x, y, feature_magnitude[i]])\n",
        "\n",
        "        return np.array(tree_coords) if tree_coords else np.array([])\n",
        "\n",
        "    def estimate_tree_heights(self, tree_coords, features, image,\n",
        "                            ground_sample_distance=0.5):  # meters per pixel\n",
        "        \"\"\"\n",
        "        Estimate tree heights using feature analysis\n",
        "        This is a simplified approach - in practice you'd need stereo imagery or LiDAR\n",
        "        \"\"\"\n",
        "        if len(tree_coords) == 0:\n",
        "            return []\n",
        "\n",
        "        heights = []\n",
        "        patch_size = int(np.sqrt(len(features)))\n",
        "\n",
        "        for coord in tree_coords:\n",
        "            x, y, intensity = coord\n",
        "            patch_idx = int(y * patch_size + x)\n",
        "\n",
        "            # Get feature vector for this tree\n",
        "            tree_feature = features[patch_idx]\n",
        "\n",
        "            # Simple height estimation based on feature characteristics\n",
        "            # This is a placeholder - real height estimation requires more sophisticated methods\n",
        "            base_height = 5.0  # minimum tree height in meters\n",
        "            height_factor = intensity / np.max(tree_coords[:, 2])  # normalized intensity\n",
        "            estimated_height = base_height + (height_factor * 25.0)  # max 30m trees\n",
        "\n",
        "            heights.append(estimated_height)\n",
        "\n",
        "        return np.array(heights)\n",
        "\n",
        "    def cluster_tree_crowns(self, tree_coords, eps=2.0, min_samples=3):\n",
        "        \"\"\"\n",
        "        Cluster nearby tree points to identify individual tree crowns\n",
        "        \"\"\"\n",
        "        if len(tree_coords) < min_samples:\n",
        "            return []\n",
        "\n",
        "        # Use DBSCAN clustering\n",
        "        clustering = DBSCAN(eps=eps, min_samples=min_samples)\n",
        "        clusters = clustering.fit_predict(tree_coords[:, :2])\n",
        "\n",
        "        tree_crowns = []\n",
        "        for cluster_id in set(clusters):\n",
        "            if cluster_id != -1:  # -1 is noise\n",
        "                cluster_points = tree_coords[clusters == cluster_id]\n",
        "                # Calculate crown center and radius\n",
        "                center = np.mean(cluster_points[:, :2], axis=0)\n",
        "                max_intensity = np.max(cluster_points[:, 2])\n",
        "                tree_crowns.append({\n",
        "                    'center': center,\n",
        "                    'points': cluster_points,\n",
        "                    'intensity': max_intensity\n",
        "                })\n",
        "\n",
        "        return tree_crowns\n",
        "\n",
        "    def visualize_results(self, image, tree_coords, tree_crowns, heights):\n",
        "        \"\"\"Visualize detected trees and estimated heights with proper scaling\"\"\"\n",
        "        # Create figure with larger size for better visibility\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
        "\n",
        "        # Get scaling information\n",
        "        patch_grid_size = self.image_metadata['patch_grid_size']\n",
        "        original_width, original_height = self.image_metadata['original_size']\n",
        "\n",
        "        # Calculate scaling factors from patch coordinates to original image coordinates\n",
        "        scale_x = original_width / patch_grid_size\n",
        "        scale_y = original_height / patch_grid_size\n",
        "\n",
        "        print(f\"Patch grid: {patch_grid_size}x{patch_grid_size}\")\n",
        "        print(f\"Scaling factors: x={scale_x:.2f}, y={scale_y:.2f}\")\n",
        "\n",
        "        # Plot 1: Original image with tree points\n",
        "        ax1.imshow(image)\n",
        "        ax1.set_title(f'Detected Tree Points\\nOriginal Size: {original_width}x{original_height}', fontsize=14)\n",
        "\n",
        "        if len(tree_coords) > 0:\n",
        "            # Scale patch coordinates to original image coordinates\n",
        "            scaled_coords = tree_coords[:, :2].copy()\n",
        "            scaled_coords[:, 0] *= scale_x  # x coordinates\n",
        "            scaled_coords[:, 1] *= scale_y  # y coordinates\n",
        "\n",
        "            # Plot tree points with intensity-based coloring\n",
        "            intensities = tree_coords[:, 2]\n",
        "            scatter1 = ax1.scatter(scaled_coords[:, 0], scaled_coords[:, 1],\n",
        "                                c=intensities, cmap='Reds', s=50, alpha=0.8,\n",
        "                                edgecolors='white', linewidth=1)\n",
        "            plt.colorbar(scatter1, ax=ax1, label='Feature Intensity')\n",
        "\n",
        "            # Add text showing number of points\n",
        "            ax1.text(0.02, 0.98, f'Tree points: {len(tree_coords)}',\n",
        "                    transform=ax1.transAxes, verticalalignment='top',\n",
        "                    bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
        "\n",
        "        # Plot 2: Tree crowns with height estimates\n",
        "        ax2.imshow(image)\n",
        "        ax2.set_title(f'Tree Crowns with Height Estimates\\nCrowns: {len(tree_crowns)}', fontsize=14)\n",
        "\n",
        "        if tree_crowns and len(heights) > 0:\n",
        "            max_height = np.max(heights)\n",
        "            min_height = np.min(heights)\n",
        "\n",
        "            for i, crown in enumerate(tree_crowns):\n",
        "                if i < len(heights):\n",
        "                    # Scale crown center to original image coordinates\n",
        "                    center = crown['center'].copy()\n",
        "                    center[0] *= scale_x\n",
        "                    center[1] *= scale_y\n",
        "\n",
        "                    height = heights[i]\n",
        "\n",
        "                    # Color based on height (normalized)\n",
        "                    height_norm = (height - min_height) / (max_height - min_height) if max_height > min_height else 0.5\n",
        "                    color = plt.cm.viridis(height_norm)\n",
        "\n",
        "                    # Draw crown circle with size based on height\n",
        "                    circle_size = 30 + (height_norm * 100)  # Size 30-130\n",
        "                    ax2.scatter(center[0], center[1], c=[color], s=circle_size,\n",
        "                            edgecolors='white', linewidth=2, alpha=0.8)\n",
        "\n",
        "                    # Add height label\n",
        "                    ax2.text(center[0], center[1] - 15, f'{height:.1f}m',\n",
        "                            ha='center', va='bottom', color='white',\n",
        "                            fontweight='bold', fontsize=10,\n",
        "                            bbox=dict(boxstyle='round,pad=0.3', facecolor='black', alpha=0.7))\n",
        "\n",
        "            # Add height statistics\n",
        "            stats_text = f'Heights: {min_height:.1f}m - {max_height:.1f}m\\nMean: {np.mean(heights):.1f}m'\n",
        "            ax2.text(0.02, 0.98, stats_text, transform=ax2.transAxes,\n",
        "                    verticalalignment='top', fontsize=10,\n",
        "                    bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
        "\n",
        "        # Remove axes ticks for cleaner look\n",
        "        ax1.set_xticks([])\n",
        "        ax1.set_yticks([])\n",
        "        ax2.set_xticks([])\n",
        "        ax2.set_yticks([])\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Print resolution information\n",
        "        print(f\"\\nImage Resolution Information:\")\n",
        "        print(f\"Original image: {original_width}x{original_height} pixels\")\n",
        "        print(f\"Processed for model: {self.input_size}x{self.input_size} pixels\")\n",
        "        print(f\"Feature patch grid: {patch_grid_size}x{patch_grid_size} patches\")\n",
        "        print(f\"Each patch represents: {scale_x:.1f}x{scale_y:.1f} pixels in original image\")\n",
        "\n",
        "    def visualize_results1(self, image, tree_coords, tree_crowns, heights):\n",
        "        \"\"\"Visualize detected trees and estimated heights\"\"\"\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 7))\n",
        "\n",
        "        # Original image with tree points\n",
        "        ax1.imshow(image)\n",
        "        ax1.set_title('Detected Tree Points')\n",
        "\n",
        "        if len(tree_coords) > 0:\n",
        "            # Scale coordinates to image size\n",
        "            img_height, img_width = image.size[1], image.size[0]\n",
        "            patch_size = int(np.sqrt(len(tree_coords)))\n",
        "\n",
        "            scale_x = img_width / patch_size\n",
        "            scale_y = img_height / patch_size\n",
        "\n",
        "            scaled_coords = tree_coords[:, :2] * [scale_x, scale_y]\n",
        "            ax1.scatter(scaled_coords[:, 0], scaled_coords[:, 1],\n",
        "                       c='red', s=30, alpha=0.7)\n",
        "\n",
        "        # Tree crowns with height color coding\n",
        "        ax2.imshow(image)\n",
        "        ax2.set_title('Tree Crowns with Height Estimates')\n",
        "\n",
        "        if tree_crowns and len(heights) > 0:\n",
        "            for i, crown in enumerate(tree_crowns):\n",
        "                if i < len(heights):\n",
        "                    center = crown['center'] * [scale_x, scale_y]\n",
        "                    height = heights[i]\n",
        "\n",
        "                    # Color based on height\n",
        "                    color = plt.cm.viridis(height / np.max(heights))\n",
        "                    ax2.scatter(center[0], center[1], c=[color], s=100,\n",
        "                               edgecolors='white', linewidth=2)\n",
        "                    ax2.text(center[0], center[1] - 20, f'{height:.1f}m',\n",
        "                            ha='center', va='bottom', color='white', fontweight='bold')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def analyze_forest_area(self, image_path):\n",
        "        \"\"\"\n",
        "        Complete analysis pipeline for forest area\n",
        "        \"\"\"\n",
        "        print(\"Extracting features from aerial imagery...\")\n",
        "        features, image = self.extract_features(image_path)\n",
        "\n",
        "        print(\"Detecting tree points...\")\n",
        "        tree_coords = self.detect_tree_points(features)\n",
        "\n",
        "        if len(tree_coords) == 0:\n",
        "            print(\"No trees detected in the image.\")\n",
        "            return None\n",
        "\n",
        "        print(f\"Found {len(tree_coords)} potential tree locations\")\n",
        "\n",
        "        print(\"Clustering tree crowns...\")\n",
        "        tree_crowns = self.cluster_tree_crowns(tree_coords)\n",
        "        print(f\"Identified {len(tree_crowns)} individual tree crowns\")\n",
        "\n",
        "        print(\"Estimating tree heights...\")\n",
        "        heights = self.estimate_tree_heights(tree_coords, features, image)\n",
        "\n",
        "        # Results summary\n",
        "        results = {\n",
        "            'num_trees': len(tree_crowns),\n",
        "            'tree_coordinates': tree_coords,\n",
        "            'tree_crowns': tree_crowns,\n",
        "            'estimated_heights': heights,\n",
        "            'mean_height': np.mean(heights) if len(heights) > 0 else 0,\n",
        "            'max_height': np.max(heights) if len(heights) > 0 else 0\n",
        "        }\n",
        "\n",
        "        print(f\"\\nAnalysis Results:\")\n",
        "        print(f\"Number of trees detected: {results['num_trees']}\")\n",
        "        print(f\"Mean tree height: {results['mean_height']:.2f}m\")\n",
        "        print(f\"Maximum tree height: {results['max_height']:.2f}m\")\n",
        "\n",
        "        # Visualize results\n",
        "        self.visualize_results(image, tree_coords, tree_crowns, heights)\n",
        "\n",
        "        return results"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0d42984"
      },
      "source": [
        "### 3.  Usage (`main` function)\n",
        "\n",
        "This section provides how to use the `DINOv3TreeAnalyzer` class with a single image. It initializes the analyzer, calls the `analyze_forest_area` method, and saves the results to CSV files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1c6a8ba3"
      },
      "source": [
        "#  usage\n",
        "def main():\n",
        "    # Initialize the analyzer\n",
        "    analyzer = DINOv3TreeAnalyzer(model_size='large')\n",
        "\n",
        "    # For demonstration, let's create a sample workflow\n",
        "    # In practice, you would use your own aerial/satellite imagery\n",
        "\n",
        "    # Example with a forest image (you need to provide your own image path)\n",
        "    image_path = \"\"\n",
        "\n",
        "    try:\n",
        "        results = analyzer.analyze_forest_area(image_path)\n",
        "\n",
        "        if results:\n",
        "            # Export results\n",
        "            np.savetxt('tree_coordinates.csv', results['tree_coordinates'],\n",
        "                      delimiter=',', header='x,y,intensity')\n",
        "            np.savetxt('tree_heights.csv', results['estimated_heights'],\n",
        "                      delimiter=',', header='height_meters')\n",
        "\n",
        "            print(\"Results saved to CSV files\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(\"Please provide a valid image path\")\n",
        "        print(\"Example usage with a sample image:\")\n",
        "        print(\"1. Download aerial/satellite imagery of a forest area\")\n",
        "        print(\"2. Update the image_path variable\")\n",
        "        print(\"3. Run the analysis\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5daf971"
      },
      "source": [
        "### 4. Advanced Usage (`batch_process_forest_images` function)\n",
        "\n",
        "This function demonstrates how to process multiple forest images in a batch. It iterates through a directory of images, processes each one using the `DINOv3TreeAnalyzer`, and saves the individual results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f90af598"
      },
      "source": [
        "# Advanced usage for batch processing\n",
        "def batch_process_forest_images(image_directory, output_directory):\n",
        "    \"\"\"Process multiple forest images in batch\"\"\"\n",
        "    analyzer = DINOv3TreeAnalyzer(model_size='base')\n",
        "\n",
        "    results_summary = []\n",
        "\n",
        "    for filename in os.listdir(image_directory):\n",
        "        if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.tiff')):\n",
        "            image_path = os.path.join(image_directory, filename)\n",
        "            print(f\"Processing {filename}...\")\n",
        "\n",
        "            try:\n",
        "                results = analyzer.analyze_forest_area(image_path)\n",
        "                if results:\n",
        "                    results['filename'] = filename\n",
        "                    results_summary.append(results)\n",
        "\n",
        "                    # Save individual results\n",
        "                    base_name = os.path.splitext(filename)[0]\n",
        "                    np.savetxt(\n",
        "                        os.path.join(output_directory, f'{base_name}_trees.csv'),\n",
        "                        results['tree_coordinates'],\n",
        "                        delimiter=',',\n",
        "                        header='x,y,intensity'\n",
        "                    )\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {filename}: {e}\")\n",
        "\n",
        "    return results_summary"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8fc2cfb"
      },
      "source": [
        "### 5. Main Execution Block\n",
        "\n",
        "This block checks if the script is being run directly and, if so, calls the `main` function to execute the example usage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93848aec",
        "outputId": "313759fb-6a6e-4ef3-8009-b55ece2bc8b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://github.com/facebookresearch/dinov3/zipball/main\" to /root/.cache/torch/hub/main.zip\n",
            "Loading DINOv2 as fallback (install DINOv3 for best results)\n",
            "Downloading: \"https://github.com/facebookresearch/dinov2/zipball/main\" to /root/.cache/torch/hub/main.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n",
            "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
            "/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:33: UserWarning: xFormers is not available (Attention)\n",
            "  warnings.warn(\"xFormers is not available (Attention)\")\n",
            "/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:40: UserWarning: xFormers is not available (Block)\n",
            "  warnings.warn(\"xFormers is not available (Block)\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://dl.fbaipublicfiles.com/dinov2/dinov2_vitl14/dinov2_vitl14_pretrain.pth\" to /root/.cache/torch/hub/checkpoints/dinov2_vitl14_pretrain.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.13G/1.13G [00:14<00:00, 81.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting features from aerial imagery...\n",
            "Please provide a valid image path\n",
            "Example usage with a sample image:\n",
            "1. Download aerial/satellite imagery of a forest area\n",
            "2. Update the image_path variable\n",
            "3. Run the analysis\n"
          ]
        }
      ]
    }
  ]
}